{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TTF4iRVqL9yy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import exp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "InputNodes = 2\n",
        "HiddenNodes = 2\n",
        "OutputNodes = 1\n",
        "\n",
        "Input = np.array([[0,0],\n",
        "                  [0,1],\n",
        "                  [1,0],\n",
        "                  [1,1]])\n",
        "\n",
        "Target = np.array([[0],\n",
        "                   [1],\n",
        "                   [1],\n",
        "                   [0]])"
      ],
      "metadata": {
        "id": "GXSmHkMPMQVq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "w1 = np.random.uniform(-0.1, 0.1, (2, 2))  # Weights for input to hidden layer\n",
        "b1 = np.random.uniform(-0.1, 0.1, (1, 2))  # Biases for hidden layer\n",
        "w2 = np.random.uniform(-0.1, 0.1, (2, 1))  # Weights for hidden layer to output\n",
        "b2 = np.random.uniform(-0.1, 0.1, (1, 1))  # Biases for output layer"
      ],
      "metadata": {
        "id": "l0AoZUHiNHob"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "I_XTf_0zOJDI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the sigmoid activation function for input x\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Compute the derivative of the sigmoid function for input sigmoid(x)\n",
        "# Note that we are passing sigmoid(x), not x, to the function\n",
        "def sigmoid_derivative(s_x):\n",
        "    return np.multiply(s_x, np.subtract(1.0, s_x))"
      ],
      "metadata": {
        "id": "0j86gKo-OO-Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the main training process"
      ],
      "metadata": {
        "id": "RAMKX-0HtQD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100000):\n",
        "    perm = np.random.permutation(len(Input))\n",
        "    Input = Input[perm]\n",
        "    Target = Target[perm]\n",
        "\n",
        "    total_error = 0\n",
        "\n",
        "    for i in range(len(Input)):\n",
        "        # To-Do\n",
        "        # Forward pass\n",
        "        # calculate the hidden_layer activation\n",
        "        hidden_layer = sigmoid(np.dot(Input[i], w1) + b1)\n",
        "        # calculate the output_layer activation\n",
        "        output_layer = sigmoid(np.dot(hidden_layer, w2) + b2)\n",
        "\n",
        "        # Calculate error\n",
        "        # compare the target[i] with output_layer activation\n",
        "        error = Target[i] - output_layer\n",
        "        # adding errors to total_error\n",
        "        total_error += np.mean(error ** 2)\n",
        "\n",
        "        # Backpropagation\n",
        "        # compute the output_layer_delta\n",
        "        output_layer_delta = error * sigmoid_derivative(output_layer)\n",
        "        # compute the hidden_layer_delta\n",
        "        hidden_layer_delta = output_layer_delta.dot(w2.T) * sigmoid_derivative(hidden_layer)\n",
        "\n",
        "        # Update weights and biases\n",
        "        # update the weights with activation, delta, and the learning rate\n",
        "        w1 += Input[i].reshape(-1, 1) * hidden_layer_delta * learning_rate\n",
        "        b1 += hidden_layer_delta * learning_rate\n",
        "        w2 += hidden_layer.reshape(-1, 1) * output_layer_delta * learning_rate\n",
        "        b2 += output_layer_delta * learning_rate\n",
        "\n",
        "    # Check if error is less than 0.25\n",
        "    if total_error < 0.25:\n",
        "        print (\"Earlier termination on epoch:\", epoch)\n",
        "        break"
      ],
      "metadata": {
        "id": "Il50-RJPOTo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0dbf820-aa0a-4cd7-bf9f-593069b1d1a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earlier termination on epoch: 19660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output the learned function for the 4 inputs"
      ],
      "metadata": {
        "id": "X4Kn0z6VtETw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   for i in range(len(Input)):\n",
        "        # Forward pass\n",
        "        # calculate the hidden_layer activation\n",
        "        hidden_layer = sigmoid(np.dot(Input[i], w1) + b1)\n",
        "        # calculate the output_layer activation\n",
        "        output_layer = sigmoid(np.dot(hidden_layer, w2) + b2)\n",
        "        # print the input[i] and the learned output\n",
        "        print (Input[i],output_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ggyQvRumJvC",
        "outputId": "fc40501d-4299-4395-e968-c8d8cf7ac365"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0] [[0.77000114]]\n",
            "[1 1] [[0.34811437]]\n",
            "[0 1] [[0.76988032]]\n",
            "[0 0] [[0.14167664]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final weights (w1):\\n\", w1)\n",
        "print(\"Final weights (b1):\\n\", b1)\n",
        "print(\"Final weights (w2):\\n\", w2)\n",
        "print(\"Final weights (b2):\\n\", b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiA8YdtXOuUh",
        "outputId": "2ac289d4-0300-41f1-dc0b-b58da4dd4c08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final weights (w1):\n",
            " [[-4.99131392 -2.11626152]\n",
            " [-5.00086726 -2.11826092]]\n",
            "Final weights (b1):\n",
            " [[1.24760675 2.77536569]]\n",
            "Final weights (w2):\n",
            " [[-5.555635  ]\n",
            " [ 4.17293745]]\n",
            "Final weights (b2):\n",
            " [[-1.41345375]]\n"
          ]
        }
      ]
    }
  ]
}